{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, print_function, unicode_literals\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "def white_balance_loops(img):\n",
    "    result = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    avg_a = np.average(result[:, :, 1])\n",
    "    avg_b = np.average(result[:, :, 2])\n",
    "    for x in range(result.shape[0]):\n",
    "        for y in range(result.shape[1]):\n",
    "            l, a, b = result[x, y, :]\n",
    "            # fix for CV correction\n",
    "            l *= 100 / 255.0\n",
    "            result[x, y, 1] = a - ((avg_a - 128) * (l / 100.0) * 1.1)\n",
    "            result[x, y, 2] = b - ((avg_b - 128) * (l / 100.0) * 1.1)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_LAB2BGR)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### white balance\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.ndimage\n",
    "import sys\n",
    "\n",
    "def apply_mask(matrix, mask, fill_value):\n",
    "    masked = np.ma.array(matrix, mask=mask, fill_value=fill_value)\n",
    "    return masked.filled()\n",
    "\n",
    "def apply_threshold(matrix, low_value, high_value):\n",
    "    low_mask = matrix < low_value\n",
    "    matrix = apply_mask(matrix, low_mask, low_value)\n",
    "\n",
    "    high_mask = matrix > high_value\n",
    "    matrix = apply_mask(matrix, high_mask, high_value)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def simplest_cb(img, percent=1):\n",
    "    assert img.shape[2] == 3\n",
    "    assert percent > 0 and percent < 100\n",
    "\n",
    "    half_percent = percent / 200.0\n",
    "\n",
    "    channels = cv2.split(img)\n",
    "\n",
    "    out_channels = []\n",
    "    for channel in channels:\n",
    "        assert len(channel.shape) == 2\n",
    "        # find the low and high precentile values (based on the input percentile)\n",
    "        height, width = channel.shape\n",
    "        vec_size = width * height\n",
    "        flat = channel.reshape(vec_size)\n",
    "\n",
    "        assert len(flat.shape) == 1\n",
    "\n",
    "        flat = np.sort(flat)\n",
    "\n",
    "        n_cols = flat.shape[0]\n",
    "\n",
    "        low_val  = flat[math.floor(n_cols * half_percent)]\n",
    "        high_val = flat[math.ceil( n_cols * (1.0 - half_percent))]\n",
    "\n",
    "        # saturate below the low percentile and above the high percentile\n",
    "        thresholded = apply_threshold(channel, low_val, high_val)\n",
    "        # scale the channel\n",
    "        normalized = cv2.normalize(thresholded, thresholded.copy(), 0, 255, cv2.NORM_MINMAX)\n",
    "        out_channels.append(normalized)\n",
    "\n",
    "    return cv2.merge(out_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmark detection & Target Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_PATH = r\"C:\\Users\\82107\\Desktop\\CatchTone-master\\shape_predictor_68_face_landmarks.dat\\shape_predictor_68_face_landmarks.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR = 1 \n",
    "FEATHER_AMOUNT = 11\n",
    "\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "JAW_POINTS = list(range(0, 17))\n",
    "\n",
    "# Points used to line up the images.\n",
    "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
    "                               RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TooManyFaces(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoFaces(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_im_and_landmarks(fname):\n",
    "    im = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (im.shape[1] * SCALE_FACTOR, im.shape[0] * SCALE_FACTOR))\n",
    "    landmarks = get_landmarks(im)\n",
    "\n",
    "    return im, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "        \n",
    "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"dark\"\n",
    "img_type = \"jpg\" ## jpg or png etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im, landmarks = read_im_and_landmarks(r\"C:\\Users\\82107\\Desktop\\CatchTone-master\\KakaoTalk_20190910_220013777.jpg\")\n",
    "\n",
    "im_annotated = annotate_landmarks(im, landmarks)\n",
    "\n",
    "cv2.imwrite(r\"C:\\Users\\82107\\Desktop\\CatchTone-master\\result\\\\\" + filename + \"_landmarks.jpg\", im_annotated) # save landmarked image file as ~_landmarks.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_location1 = ((landmarks[54]+landmarks[11]+landmarks[45])/3).astype(int) # left cheek\n",
    "color_location2 = ((landmarks[48]+landmarks[4]+landmarks[36])/3).astype(int) # right cheek\n",
    "\n",
    "rgb1 = im[color_location1[0, 1], color_location1[0, 0]][2], im[color_location1[0, 1], color_location1[0, 0]][1], im[color_location1[0, 1], color_location1[0, 0]][0]\n",
    "rgb2 = im[color_location2[0, 1], color_location2[0, 0]][2], im[color_location2[0, 1], color_location2[0, 0]][1], im[color_location2[0, 1], color_location2[0, 0]][0]\n",
    "\n",
    "rgb = ((int(rgb1[0])+int(rgb2[0]))/2, (int(rgb1[1])+int(rgb2[1]))/2, (int(rgb1[2])+int(rgb2[2]))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 26,  21,  22],\n",
       "        [ 26,  21,  22],\n",
       "        [ 27,  22,  23],\n",
       "        ...,\n",
       "        [ 31,  23,  24],\n",
       "        [ 28,  21,  18],\n",
       "        [ 33,  27,  22]],\n",
       "\n",
       "       [[ 29,  23,  24],\n",
       "        [ 24,  19,  20],\n",
       "        [ 24,  19,  20],\n",
       "        ...,\n",
       "        [ 31,  23,  23],\n",
       "        [ 27,  19,  19],\n",
       "        [ 40,  32,  32]],\n",
       "\n",
       "       [[ 26,  21,  20],\n",
       "        [ 25,  19,  20],\n",
       "        [ 25,  20,  21],\n",
       "        ...,\n",
       "        [ 30,  22,  23],\n",
       "        [ 29,  21,  21],\n",
       "        [ 32,  25,  22]]], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.putText(im, str(\"Target1\"), (color_location1[0, 0]+5, color_location1[0, 1]),\n",
    "                    fontFace=cv2.FONT_HERSHEY_TRIPLEX,\n",
    "                    fontScale=0.5,\n",
    "                    color=(0, 0, 255))\n",
    "cv2.circle(im, (color_location1[0, 0], color_location1[0, 1]), 3, color=(0, 0, 255), thickness = -1)\n",
    "\n",
    "cv2.putText(im, str(\"Target2\"), (color_location2[0, 0]+5, color_location2[0, 1]),\n",
    "                    fontFace=cv2.FONT_HERSHEY_TRIPLEX,\n",
    "                    fontScale=0.5,\n",
    "                    color=(0, 0, 255))\n",
    "cv2.circle(im, (color_location2[0, 0], color_location2[0, 1]), 3, color=(0, 0, 255), thickness = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_annotated = annotate_landmarks(im, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(r\"C:\\Users\\82107\\Desktop\\CatchTone-master\\result\\\\\" + filename + \"_target.jpg\", im_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a\\* b\\* value comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(filename+\".\"+img_type)\n",
    "lab_colors = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_value1 = lab_colors[color_location1[0, 1], color_location1[0, 0]][1]\n",
    "a_value2 = lab_colors[color_location2[0, 1], color_location2[0, 0]][1]\n",
    "\n",
    "a_value = (int(a_value1) + int(a_value2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_value1 = lab_colors[color_location1[0, 1], color_location1[0, 0]][2]\n",
    "b_value2 = lab_colors[color_location2[0, 1], color_location2[0, 0]][2]\n",
    "\n",
    "b_value = (int(b_value1) + int(b_value2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('classifier.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_ab_value = []\n",
    "\n",
    "info = []\n",
    "info.append(a_value)\n",
    "info.append(b_value)\n",
    "\n",
    "skin_ab_value.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def warm_or_cool(skin_ab_value):\n",
    "    value = loaded_model.predict(skin_ab_value)\n",
    "    \n",
    "    if value == 0:\n",
    "        return \"warm\"\n",
    "    else:\n",
    "        return \"cool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_ab_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlim(120, 160)\n",
    "plt.ylim(120, 170)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Eye Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_eyes(im,landmarks):\n",
    "    im = im[landmarks[37][0, 1]+1:landmarks[40][0, 1]+1, landmarks[37][0, 0]-2:landmarks[38][0, 0]+3, :]\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_eyes = cut_eyes(im, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('./result/'+filename+'_eye.jpg', cut_eyes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pupil & Light (on Eye) Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "gray = cv2.cvtColor(cut_eyes, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gray_resized = np.resize(gray, [gray.shape[0]*gray.shape[1]])\n",
    "n, bins, patches = plt.hist(gray_resized, bins=80, color='black')\n",
    "\n",
    "plt.xlabel(\"Grayscale value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Assuming Dark Eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light on eye Detection (thresh = 90)\n",
    "\n",
    "etval, thresholded = cv2.threshold(gray, 90, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dark = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < cut_eyes.shape[0]:\n",
    "    j = 0\n",
    "    index_of_black = []\n",
    "    while j < cut_eyes.shape[1]:\n",
    "        if thresholded[i][j] == 0:\n",
    "            index_of_black.append(i)\n",
    "            index_of_black.append(j)\n",
    "            index_dark.append(index_of_black)\n",
    "            index_of_black = []\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pupil Detection (thresh = 20)\n",
    "etval, thresholded = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < cut_eyes.shape[0]:\n",
    "    j = 0\n",
    "    index_deleted = []\n",
    "    while j < cut_eyes.shape[1]:\n",
    "        if thresholded[i][j] == 0:\n",
    "            index_deleted.append(i)\n",
    "            index_deleted.append(j)\n",
    "            if index_deleted in index_dark:\n",
    "                index_dark.remove(index_deleted)\n",
    "            index_deleted = []\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Assuming Medium Brightness Eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light on eye Detection (thresh = 140)\n",
    "\n",
    "etval, thresholded = cv2.threshold(gray, 140, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_medium = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < cut_eyes.shape[0]:\n",
    "    j = 0\n",
    "    index_of_black = []\n",
    "    while j < cut_eyes.shape[1]:\n",
    "        if thresholded[i][j] == 0:\n",
    "            index_of_black.append(i)\n",
    "            index_of_black.append(j)\n",
    "            index_medium.append(index_of_black)\n",
    "            index_of_black = []\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pupil Detection (thresh = 50)\n",
    "etval, thresholded = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < cut_eyes.shape[0]:\n",
    "    j = 0\n",
    "    index_deleted = []\n",
    "    while j < cut_eyes.shape[1]:\n",
    "        if thresholded[i][j] == 0:\n",
    "            index_deleted.append(i)\n",
    "            index_deleted.append(j)\n",
    "            if index_deleted in index_medium:\n",
    "                index_medium.remove(index_deleted)\n",
    "            index_deleted = []\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Assuming Light Eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light on eye Detection (thresh = 140)\n",
    "\n",
    "etval, thresholded = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_light = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < cut_eyes.shape[0]:\n",
    "    j = 0\n",
    "    index_of_black = []\n",
    "    while j < cut_eyes.shape[1]:\n",
    "        if thresholded[i][j] == 0:\n",
    "            index_of_black.append(i)\n",
    "            index_of_black.append(j)\n",
    "            index_light.append(index_of_black)\n",
    "            index_of_black = []\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pupil Detection (thresh = 50)\n",
    "etval, thresholded = cv2.threshold(gray, 65, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < cut_eyes.shape[0]:\n",
    "    j = 0\n",
    "    index_deleted = []\n",
    "    while j < cut_eyes.shape[1]:\n",
    "        if thresholded[i][j] == 0:\n",
    "            index_deleted.append(i)\n",
    "            index_deleted.append(j)\n",
    "            if index_deleted in index_light:\n",
    "                index_light.remove(index_deleted)\n",
    "            index_deleted = []\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Selecting which index to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of index_dark : \" + str(len(index_dark)))\n",
    "print(\"Length of index_medium : \" + str(len(index_medium)))\n",
    "print(\"Length of index_light : \" + str(len(index_light)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_index_to_use():\n",
    "    max = 0\n",
    "    name_of_index = \"\"\n",
    "    index_to_use = []\n",
    "    \n",
    "    if len(index_dark) > len(index_medium):\n",
    "        max = len(index_dark)\n",
    "        index_to_use = index_dark\n",
    "        name_of_index = \"index_dark\"\n",
    "    else:\n",
    "        max = len(index_medium)\n",
    "        index_to_use = index_medium\n",
    "        name_of_index = \"index_medium\"\n",
    "        \n",
    "    \n",
    "    if max < len(index_light):\n",
    "        print(\"index_light\")\n",
    "        index_to_use = index_light\n",
    "    else:\n",
    "        print(name_of_index)\n",
    "        \n",
    "    return index_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_use = select_index_to_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L\\*value of Eye (15% is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eye_lab = cv2.cvtColor(cut_eyes, cv2.COLOR_RGB2LAB)\n",
    "eye_l_value = []\n",
    "\n",
    "i = 0\n",
    "while i < len(index_to_use):\n",
    "    eye_l_value.append(eye_lab[index_to_use[i][0], index_to_use[i][1], 0])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < int(len(eye_l_value)*15/85):\n",
    "    eye_l_value.append(0)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You are \\\"\" + warm_or_cool(skin_ab_value) + \"\\\" tone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_l_value = np.array(eye_l_value)\n",
    "std = math.sqrt(np.sum((eye_l_value - np.mean(eye_l_value))**2)/(eye_l_value.size))\n",
    "\n",
    "eye_brightness = \"\"\n",
    "\n",
    "if std < 38.28:\n",
    "    eye_brightness = \"dark\"\n",
    "else:\n",
    "    eye_brightness = \"light\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_matching(skin_tone, eye_brightness):\n",
    "    if skin_tone == \"warm\":\n",
    "        if eye_brightness == \"dark\":\n",
    "            return \"autumn\"\n",
    "        else:\n",
    "            return \"spring\"\n",
    "    else:\n",
    "        if eye_brightness == \"dark\":\n",
    "            return \"winter\"\n",
    "        else:\n",
    "            return \"summer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season = season_matching(warm_or_cool(skin_ab_value), eye_brightness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deep? Mute? Light? Bright?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_info = [[0.87464539937997 * 255, 181, 'vivid'],\n",
    " [0.6920954876849125 * 255, 207, 'bright'],\n",
    " [0.8348038859274655 * 255, 170, 'strong'],\n",
    " [0.8901501134915047 * 255, 137, 'deep'],\n",
    " [0.3300064593086124 * 255, 221, 'light'],\n",
    " [0.39800595815638706 * 255, 182, 'soft'], \n",
    " [0.5135643825656158 * 255, 142, 'dull'],\n",
    " [0.6815737217178439 * 255, 93, 'dark'],\n",
    " [0.11073418459625402 * 255, 226, 'pale'],\n",
    " [0.22483614835441365 * 255, 110, 'grayish'],\n",
    " [0.26913149326755986 * 255, 58, 'dark_grayish'],\n",
    " [0.20022609113608203 * 255, 186, 'light_grayish']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_list = []\n",
    "spring_list.append(color_info[0])\n",
    "spring_list.append(color_info[1])\n",
    "spring_list.append(color_info[4])\n",
    "spring_list.append(color_info[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_list = []\n",
    "summer_list.append(color_info[4])\n",
    "summer_list.append(color_info[8])\n",
    "summer_list.append(color_info[5])\n",
    "summer_list.append(color_info[6])\n",
    "summer_list.append(color_info[7])\n",
    "summer_list.append(color_info[9])\n",
    "summer_list.append(color_info[10])\n",
    "summer_list.append(color_info[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autumn_list = []\n",
    "autumn_list.append(color_info[3])\n",
    "autumn_list.append(color_info[5])\n",
    "autumn_list.append(color_info[6])\n",
    "autumn_list.append(color_info[9])\n",
    "autumn_list.append(color_info[3])\n",
    "autumn_list.append(color_info[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_list = []\n",
    "winter_list.append(color_info[0])\n",
    "winter_list.append(color_info[2])\n",
    "winter_list.append(color_info[3])\n",
    "winter_list.append(color_info[7])\n",
    "winter_list.append(color_info[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_v_value = max(rgb[0], rgb[1], rgb[2])\n",
    "skin_s_value = (1-min(rgb[0], rgb[1], rgb[2])/skin_v_value) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skin_s_value, skin_v_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pccs_finder(season, s, v):\n",
    "    i = 0\n",
    "    min = 2000\n",
    "    skin_type = \"\"\n",
    "    \n",
    "    if season == \"spring\":\n",
    "        while i < len(spring_list):\n",
    "            distance = math.sqrt((s - spring_list[i][0])**2 + (v - spring_list[i][1])**2)\n",
    "            print(distance)\n",
    "            if min > distance:\n",
    "                min = distance\n",
    "                print(\"Calculating... \" + spring_list[i][2] + \" : \" + str(distance))\n",
    "                skin_type = spring_list[i][2]\n",
    "        \n",
    "            i += 1\n",
    "    \n",
    "    elif season == \"summer\":\n",
    "        while i < len(summer_list):\n",
    "            distance = math.sqrt((s - summer_list[i][0])**2 + (v - summer_list[i][1])**2)\n",
    "            print(distance)\n",
    "            if min > distance:\n",
    "                min = distance\n",
    "                print(\"Calculating... \" + summer_list[i][2] + \" : \" + str(distance))\n",
    "                skin_type = summer_list[i][2]\n",
    "        \n",
    "            i += 1\n",
    "            \n",
    "    elif season == \"autumn\":\n",
    "        while i < len(autumn_list):\n",
    "            distance = math.sqrt((s - autumn_list[i][0])**2 + (v - autumn_list[i][1])**2)\n",
    "            print(distance)\n",
    "            if min > distance:\n",
    "                min = distance\n",
    "                print(\"Calculating... \" + autumn_list[i][2] + \" : \" + str(distance))\n",
    "                skin_type = autumn_list[i][2]\n",
    "        \n",
    "            i += 1\n",
    "    \n",
    "    else:\n",
    "        while i < len(winter_list):\n",
    "            distance = math.sqrt((s - winter_list[i][0])**2 + (v - winter_list[i][1])**2)\n",
    "            if min > distance:\n",
    "                min = distance\n",
    "                print(\"Calculating... \" + winter_list[i][2] + \" : \" + str(distance))\n",
    "                skin_type = winter_list[i][2]\n",
    "        \n",
    "            i += 1\n",
    "    \n",
    "    return skin_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pccs = pccs_finder(color_info, skin_s_value, skin_v_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You are \" + pccs + \" \\\"\" + season+\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_ab_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
